#pragma once
#include<layers/InputLayer.hpp>
#include<layers/BatchTensorDNNlayer.hpp>
#include<layers/SkipConnection.hpp>
#include<layers/FlattenLayer.hpp>
#include<layers/UnflattenLayer.hpp>
#include<layers/ConvolutionLayer1D.hpp>
#include<layers/SoftMaxLayer.hpp>
#include<layers/MatrixTensorContractLayer.hpp>
#include<layers/ScaledDotProductSelfAttentionLayer.hpp>
#include<layers/MultiHeadSelfAttentionLayer.hpp>
#include<layers/MultiHeadCrossAttentionLayer.hpp>
#include<layers/NormLayer.hpp>
#include<layers/TransformerEncoderDecoderBlock.hpp>
#include<layers/EmbedPositionsSinusoidalLayer.hpp>
#include<layers/PairSplitLayer.hpp>
#include<layers/PairJoinLayer.hpp>
#include<layers/ReplicateLayer.hpp>
#include<layers/SumJoinLayer.hpp>
#include<layers/PipelineBlockLayer.hpp>
#include<layers/ComponentLayerWrapper.hpp>
#include<layers/GCNblock.hpp>
